{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy all the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.feature import hog\n",
    "get_ipython().magic('matplotlib inline')\n",
    "from scipy.ndimage.measurements import label\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data used for training and testing various machine learning models\n",
    "Data downloaded from University of California website https://archive.ics.uci.edu/ml/datasets/Poker+Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39727\n",
      "39727\n",
      "(39727, 10)\n",
      "(39727, 1)\n",
      "['2' '11' '2' '13' '2' '10' '2' '12' '2' '1']\n",
      "['9']\n",
      "(39727, 85)\n",
      "(39727, 10)\n",
      "(39727, 1)\n"
     ]
    }
   ],
   "source": [
    "with open('./poker_train_data1.csv', encoding=\"utf8\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    #next(reader, None)  # skip the header\n",
    "    xxx=[]\n",
    "    for line in reader:\n",
    "        xxx.append(line)\n",
    "with open('./poker_out3.csv', encoding=\"utf8\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    #next(reader, None)  # skip the header\n",
    "    yyy=[]\n",
    "    for line in reader:\n",
    "        yyy.append(line)\n",
    "#Augmenting the data by repeting the same data, so that every class should have minumum 2000 examples\n",
    "repeat = [1,1,2,5,21,41,41,401,401,401]\n",
    "xx = []\n",
    "yy = []\n",
    "for x,y in zip(xxx,yyy):\n",
    "    for i in range(repeat[int(y[0])]):\n",
    "        xx.append(x)\n",
    "        yy.append(y)\n",
    "print(len(xx))\n",
    "print(len(yy))\n",
    "#Connvert the data into numpy array\n",
    "X= np.asarray(xx)\n",
    "Y= np.asarray(yy)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X[0])\n",
    "print(Y[0])\n",
    "#Connvert the data to integer\n",
    "X = X.astype(np.int32)\n",
    "Y = Y.astype(np.int32)\n",
    "YY = np.copy(Y)\n",
    "#One hot encoding for the catogorical data\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "Y = ohe.fit_transform(Y)\n",
    "X = ohe.fit_transform(X)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(YY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data used fro validating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239029\n",
      "239029\n",
      "(239029, 10)\n",
      "(239029, 1)\n",
      "(239029, 85)\n",
      "(239029, 10)\n"
     ]
    }
   ],
   "source": [
    "with open('./datpoker_X.csv', encoding=\"utf8\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    #next(reader, None)  # skip the header\n",
    "    xxxx=[]\n",
    "    for line in reader:\n",
    "        xxxx.append(line)\n",
    "with open('./datpoker_y.csv', encoding=\"utf8\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    #next(reader, None)  # skip the header\n",
    "    yyyy=[]\n",
    "    for line in reader:\n",
    "        yyyy.append(line)\n",
    "print(len(xxxx))\n",
    "print(len(yyyy))\n",
    "#Connvert the data into numpy array\n",
    "X_val= np.asarray(xxxx)\n",
    "Y_val= np.asarray(yyyy)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "#Connvert the data to integer\n",
    "X_val = X_val.astype(np.int32)\n",
    "Y_val = Y_val.astype(np.int32)\n",
    "YY_val = np.copy(Y_val)\n",
    "#One hot encoding for the catogorical data\n",
    "ohe1 = OneHotEncoder(sparse=False)\n",
    "Y_val = ohe1.fit_transform(Y_val)\n",
    "X_val = ohe1.fit_transform(X_val)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into Train and Test (ratio 80:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=22)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, YY, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC Linear Model - giving very poor accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dsingh\\AppData\\Local\\Continuum\\Anaconda3\\envs\\carnd-term11\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08 Seconds to train SVC...\n",
      "Valid Accuracy of SVC =  0.216586961993\n",
      "Test Accuracy of SVC =  0.0314104146359\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(loss='hinge') # Use a linear SVC \n",
    "t=time.time() # Check the training time for the SVC\n",
    "svc.fit(X_train1, y_train1) # Train the classifier\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "print('Valid Accuracy of SVC = ', svc.score(X_test1, y_test1))\n",
    "print('Test Accuracy of SVC = ', svc.score(X_val, YY_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bays model, very low accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dsingh\\AppData\\Local\\Continuum\\Anaconda3\\envs\\carnd-term11\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04 Seconds to train NB...\n",
      "Valid Accuracy of NB :  0.231059652655\n",
      "Test Accuracy of NB :  0.0214911161407\n"
     ]
    }
   ],
   "source": [
    "clf =  GaussianNB()\n",
    "t=time.time() # Check the training time for the SVC\n",
    "clf.fit(X_train1, y_train1)\n",
    "t2 = time.time()\n",
    "pred=clf.predict(X_test1)\n",
    "pred1=clf.predict(X_val)\n",
    "print(round(t2-t, 2), 'Seconds to train NB...')\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc=accuracy_score(y_test1, pred)\n",
    "acc1=accuracy_score(YY_val, pred1)\n",
    "print(\"Valid Accuracy of NB : \" , acc)\n",
    "print(\"Test Accuracy of NB : \" , acc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree model - moderate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751069720614\n",
      "0.582707537579\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf1 = tree.DecisionTreeClassifier()\n",
    "clf1.fit(X_train1, y_train1)\n",
    "pred2=clf1.predict(X_test1)\n",
    "pred3=clf1.predict(X_val)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc2=accuracy_score(y_test1, pred2)\n",
    "acc3=accuracy_score(YY_val, pred3)\n",
    "print(acc2)\n",
    "print(acc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep neural network with 3 layers - Giving 99.75% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.2202 - acc: 0.9117     \n",
      "Epoch 2/150\n",
      "31781/31781 [==============================] - 0s - loss: 0.1689 - acc: 0.9225     - ETA: 0s - loss\n",
      "Epoch 3/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.1495 - acc: 0.9294     \n",
      "Epoch 4/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.1322 - acc: 0.9371     -  - ETA: 0s  - ETA: 0s -\n",
      "Epoch 5/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.1199 - acc: 0.9424     - ETA: - ETA: 0s - loss: 0.1204 - acc: - ETA: 0s - loss: 0.1\n",
      "Epoch 6/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.1114 - acc: 0.9470     \n",
      "Epoch 7/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.1051 - acc: 0.9511     \n",
      "Epoch 8/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.1002 - acc: 0.9540     - ETA: - ETA: 0s - loss: 0.1003 - acc: 0.9\n",
      "Epoch 9/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0955 - acc: 0.9565     - ETA: 0s - loss: \n",
      "Epoch 10/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0910 - acc: 0.9593     - ETA:\n",
      "Epoch 11/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0865 - acc: 0.9614     \n",
      "Epoch 12/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0814 - acc: 0.9641     - ETA: 0s - loss: 0.0821 - acc - ETA:\n",
      "Epoch 13/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0759 - acc: 0.9675     - ETA: 0s - loss: 0.0 - E - ETA: 0s - loss: 0.0759 - \n",
      "Epoch 14/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0694 - acc: 0.9711     - ETA: 0s - loss: 0.0\n",
      "Epoch 15/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0638 - acc: 0.9741     \n",
      "Epoch 16/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0584 - acc: 0.9767     - ETA: 0s - loss: 0.0591 - ac - ETA: 0s - loss: 0.058\n",
      "Epoch 17/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0542 - acc: 0.9785     \n",
      "Epoch 18/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0509 - acc: 0.9802     \n",
      "Epoch 19/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0477 - acc: 0.9817     - - ETA: 0s - loss: 0.0477 - acc: 0.981\n",
      "Epoch 20/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0451 - acc: 0.9825     \n",
      "Epoch 21/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0422 - acc: 0.9842     \n",
      "Epoch 22/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0393 - acc: 0.9857     \n",
      "Epoch 23/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0370 - acc: 0.9863     \n",
      "Epoch 24/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0333 - acc: 0.9884     - ETA: 0s \n",
      "Epoch 25/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0295 - acc: 0.9897     \n",
      "Epoch 26/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0256 - acc: 0.9918     - ETA: 0s - loss: 0.0252 - a - ETA: 0s - loss: 0.0256 - acc: 0.9 - ETA: 0s - loss - ETA: 0s - loss: 0.0257 - acc: \n",
      "Epoch 27/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0223 - acc: 0.9929     \n",
      "Epoch 28/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0198 - acc: 0.9940     \n",
      "Epoch 29/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0179 - acc: 0.9947     - ETA: 0s - loss - ETA: 0s - loss:\n",
      "Epoch 30/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0162 - acc: 0.9952     \n",
      "Epoch 31/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0148 - acc: 0.9957     \n",
      "Epoch 32/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0136 - acc: 0.9960     \n",
      "Epoch 33/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0127 - acc: 0.9964     - ETA: 0s - loss: 0.0127 - acc: 0.996\n",
      "Epoch 34/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0122 - acc: 0.9964     - ETA: 0\n",
      "Epoch 35/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0112 - acc: 0.9968     - ETA: 0s - loss: 0.0111 - ac - ETA: 0s - loss: 0.011\n",
      "Epoch 36/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0106 - acc: 0.9970     \n",
      "Epoch 37/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0098 - acc: 0.9972     - ETA: 0s - loss: \n",
      "Epoch 38/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0094 - acc: 0.9972     \n",
      "Epoch 39/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0090 - acc: 0.9974     \n",
      "Epoch 40/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0085 - acc: 0.9974     \n",
      "Epoch 41/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0082 - acc: 0.9976     - ETA: 0s - - ETA: 0s - loss: 0.0082 - acc: 0.997\n",
      "Epoch 42/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0082 - acc: 0.9975     \n",
      "Epoch 43/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0072 - acc: 0.9979     - ETA: 1s - l - ETA: 0s - loss: 0.0070 - acc - ETA: 0 - ETA: 0s - loss: 0.0072 - acc: \n",
      "Epoch 44/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0072 - acc: 0.9978     - ETA: 0s - l\n",
      "Epoch 45/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0070 - acc: 0.9979     -\n",
      "Epoch 46/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0068 - acc: 0.9979     \n",
      "Epoch 47/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0063 - acc: 0.9982     - ETA: 0s - loss: 0.0062 - acc: 0.\n",
      "Epoch 48/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0063 - acc: 0.9982     \n",
      "Epoch 49/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0057 - acc: 0.9984     \n",
      "Epoch 50/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0054 - acc: 0.9985     \n",
      "Epoch 51/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0057 - acc: 0.9982     - ETA: 0s - loss: 0.0049\n",
      "Epoch 52/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0056 - acc: 0.9983     \n",
      "Epoch 53/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0052 - acc: 0.9985     \n",
      "Epoch 54/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0049 - acc: 0.9986     - ETA: 0s - loss: 0.0056\n",
      "Epoch 55/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0050 - acc: 0.9986     \n",
      "Epoch 56/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0047 - acc: 0.9986     - ETA: 0s - loss\n",
      "Epoch 57/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0049 - acc: 0.9985     - ETA: 0s - loss: 0.0047 - acc: 0.9 - ETA: 0s - los\n",
      "Epoch 58/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0044 - acc: 0.9986     - ETA: \n",
      "Epoch 59/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0044 - acc: 0.9986     - \n",
      "Epoch 60/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0041 - acc: 0.9987     - - ETA: 0s - los\n",
      "Epoch 61/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0042 - acc: 0.9987     - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.0042 - acc: 0\n",
      "Epoch 62/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0038 - acc: 0.9989     \n",
      "Epoch 63/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0040 - acc: 0.9989     \n",
      "Epoch 64/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0038 - acc: 0.9989     \n",
      "Epoch 65/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0039 - acc: 0.9989     \n",
      "Epoch 66/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0034 - acc: 0.9990     - ET\n",
      "Epoch 67/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0038 - acc: 0.9989     - \n",
      "Epoch 68/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0040 - acc: 0.9986     - ETA: 0s - loss - ETA: 0s - loss: 0.0\n",
      "Epoch 69/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0028 - acc: 0.9993     \n",
      "Epoch 70/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0036 - acc: 0.9988     \n",
      "Epoch 71/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0031 - acc: 0.9990     - ETA: 0s - loss\n",
      "Epoch 72/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0034 - acc: 0.9990     - ETA: 0s - loss: 0.0032 - acc:\n",
      "Epoch 73/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31781/31781 [==============================] - 1s - loss: 0.0036 - acc: 0.9990     \n",
      "Epoch 74/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0027 - acc: 0.9992     - ETA: 0s - loss: 0.0027 -\n",
      "Epoch 75/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0033 - acc: 0.9989     - ETA: 0s - loss: 0. - ETA: 0s - loss: 0.0033 - acc: - ETA: 0s \n",
      "Epoch 76/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0029 - acc: 0.9992     - ETA: 0s - loss: 0.0029 - a\n",
      "Epoch 77/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0024 - acc: 0.9993     - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.0024 - ac\n",
      "Epoch 78/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0032 - acc: 0.9990     \n",
      "Epoch 79/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0032 - acc: 0.9989     - ETA: 0s - lo - ETA: 0s - loss: 0.0026 - acc: 0. - ET\n",
      "Epoch 80/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0024 - acc: 0.9994     - ETA: 0s - loss: 0.0022 - - E \n",
      "Epoch 81/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0029 - acc: 0.9991     \n",
      "Epoch 82/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0027 - acc: 0.9991     \n",
      "Epoch 83/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0024 - acc: 0.9992     - ETA: 0s - l\n",
      "Epoch 84/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0025 - acc: 0.9993     \n",
      "Epoch 85/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0022 - acc: 0.9994     - ETA: 0s - loss: 0.0020 - acc: 0 - ETA: 0s -\n",
      "Epoch 86/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0027 - acc: 0.9990     \n",
      "Epoch 87/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0021 - acc: 0.9993     \n",
      "Epoch 88/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0025 - acc: 0.9992     - ETA: 0s\n",
      "Epoch 89/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0023 - acc: 0.9993     - ETA: 0s - loss: 0.0023 -\n",
      "Epoch 90/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0022 - acc: 0.9994     \n",
      "Epoch 91/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0023 - acc: 0.9993     - ETA: 0s - loss: 0.0023 \n",
      "Epoch 92/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0023 - acc: 0.9993     - ETA: 0s - loss: 0.0021 - acc: 0.999 - ETA - ETA: 0s - loss: 0.0024 \n",
      "Epoch 93/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0021 - acc: 0.9994     \n",
      "Epoch 94/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0023 - acc: 0.9993     \n",
      "Epoch 95/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0018 - acc: 0.9995     \n",
      "Epoch 96/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0023 - acc: 0.9993     - ETA: 0s - loss: 0.0023 - acc: 0.99\n",
      "Epoch 97/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0022 - acc: 0.9993     \n",
      "Epoch 98/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0019 - acc: 0.9995     - ETA: 0s - loss: 0.0017 - acc: - ETA: 0s - loss: 0.0017 - a\n",
      "Epoch 99/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0019 - acc: 0.9994     - ETA: 0s - loss: 0.001 - E\n",
      "Epoch 100/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0020 - acc: 0.9994     \n",
      "Epoch 101/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0020 - acc: 0.9994     \n",
      "Epoch 102/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0016 - acc: 0.9996     - ETA: 0s - loss: 0.0016 - acc: 0\n",
      "Epoch 103/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0020 - acc: 0.9994     - ETA: 0s - l - ETA: 0s - loss: 0.0022 - acc: 0. - ETA: 0s - loss: 0.0021 - acc:  - ETA: 0s - - ETA: 0s - loss: 0.0020 - acc: 0.\n",
      "Epoch 104/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0023 - acc: 0.9993     \n",
      "Epoch 105/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0017 - acc: 0.9995     \n",
      "Epoch 106/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0020 - acc: 0.9994     - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.0020 - acc: 0.\n",
      "Epoch 107/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0019 - acc: 0.9994     \n",
      "Epoch 108/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0013 - acc: 0.9997     \n",
      "Epoch 109/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0020 - acc: 0.9994     \n",
      "Epoch 110/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0025 - acc: 0.9992     - ETA: 0s - loss: 0.0021 - \n",
      "Epoch 111/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0018 - acc: 0.9994     \n",
      "Epoch 112/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0013 - acc: 0.9996     - ETA: 0s - loss: 0.0013 - acc: 0.9\n",
      "Epoch 113/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0014 - acc: 0.9996     - ETA: 0s - loss: 0\n",
      "Epoch 114/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0020 - acc: 0.9993     -\n",
      "Epoch 115/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0014 - acc: 0.9996     - ETA: 0s - loss: 0.0012\n",
      "Epoch 116/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0020 - acc: 0.9993     \n",
      "Epoch 117/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0015 - acc: 0.9996         - ETA: - ETA: 0s - loss: 0.0015 - acc: \n",
      "Epoch 118/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0016 - acc: 0.9995     \n",
      "Epoch 119/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0017 - acc: 0.9994     - ETA: 0s - loss: 0.0018 \n",
      "Epoch 120/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0018 - acc: 0.9994     - ETA: 0s - loss: 0.0018 - acc: 0.99\n",
      "Epoch 121/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0011 - acc: 0.9997     \n",
      "Epoch 122/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0011 - acc: 0.9997     - ETA: 0s - loss: 0.0011  - ETA: 0s - loss: 0.0012\n",
      "Epoch 123/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0023 - acc: 0.9991     \n",
      "Epoch 124/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0016 - acc: 0.9994     \n",
      "Epoch 125/150\n",
      "31781/31781 [==============================] - 1s - loss: 8.5795e-04 - acc: 0.9998     \n",
      "Epoch 126/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0015 - acc: 0.9995     - E\n",
      "Epoch 127/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0017 - acc: 0.9994     - ETA: 0s - loss: 0.0015 - ETA: 0s - loss: 0.0015 - ac\n",
      "Epoch 128/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0019 - acc: 0.9994     \n",
      "Epoch 129/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0012 - acc: 0.9996         - ETA: 0s - l\n",
      "Epoch 130/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0014 - acc: 0.9996     - E - ETA: 0s - loss: 0.00\n",
      "Epoch 131/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0016 - acc: 0.9995     - ETA: 0s - loss: 0.0015 - acc\n",
      "Epoch 132/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0014 - acc: 0.9996     \n",
      "Epoch 133/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0012 - acc: 0.9997     \n",
      "Epoch 134/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0018 - acc: 0.9994     \n",
      "Epoch 135/150\n",
      "31781/31781 [==============================] - 1s - loss: 9.1919e-04 - acc: 0.9998     \n",
      "Epoch 136/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0015 - acc: 0.9995     \n",
      "Epoch 137/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0012 - acc: 0.9996     \n",
      "Epoch 138/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0013 - acc: 0.9996     - ETA: 0s - loss: 0.0013 -\n",
      "Epoch 139/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0012 - acc: 0.9997         - ETA: 0s - loss: 5. - ETA: 0s - loss:\n",
      "Epoch 140/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0018 - acc: 0.9994     \n",
      "Epoch 141/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0011 - acc: 0.9996     \n",
      "Epoch 142/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0012 - acc: 0.9996     \n",
      "Epoch 143/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0017 - acc: 0.9994     \n",
      "Epoch 144/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31781/31781 [==============================] - 1s - loss: 0.0012 - acc: 0.9996     - ETA: 0s - loss: 0.0011 -  - ETA: 0s - loss: 0.0012 - a\n",
      "Epoch 145/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0014 - acc: 0.9995         - ETA: 0s - loss: 4.7896e-04 - acc: 0.999 - ETA: 0s - loss: 5.0201e-04 - ac\n",
      "Epoch 146/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0015 - acc: 0.9995         - ETA: 0s - loss: 7.2575e-04 - \n",
      "Epoch 147/150\n",
      "31781/31781 [==============================] - 1s - loss: 9.6126e-04 - acc: 0.9997     \n",
      "Epoch 148/150\n",
      "31781/31781 [==============================] - 1s - loss: 4.1860e-04 - acc: 0.9999     - ETA: 0s - loss: 4.1851e-04 - acc: 0.99\n",
      "Epoch 149/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0022 - acc: 0.9992     \n",
      "Epoch 150/150\n",
      "31781/31781 [==============================] - 1s - loss: 0.0014 - acc: 0.9995     - ETA: 0s - loss: 0.0014 - ac\n",
      "7456/7946 [===========================>..] - ETA: 0sTest Accuracy\n",
      "\n",
      "acc: 99.75%\n",
      "238464/239029 [============================>.] - ETA: 0sValid Accuracy\n",
      "\n",
      "acc: 99.42%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=85, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, batch_size=30, nb_epoch=150)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy\")\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "scores1 = model.evaluate(X_val, Y_val)\n",
    "print(\"Valid Accuracy\")\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores1[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('poker_model_weights.h5')\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "for layer in model.layers:\n",
    "    weights.append(layer.get_weights()) # list of numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "wts = np.asarray(weights)\n",
    "print(wts[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
